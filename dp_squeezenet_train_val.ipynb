{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dp_squeezenet_train_val.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deathboydmi/DynamicChannelPruning/blob/master/dp_squeezenet_train_val.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvfzQjO6SuhM",
        "colab_type": "code",
        "outputId": "207a9377-74ca-4e40-9227-328b6257f4e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!python3 --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRrLMoXAgKpx",
        "colab_type": "code",
        "outputId": "ebda73ff-d924-448e-e1cb-7c1d1e6b16df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!pip3 install torch==1.1.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.1.0) (1.16.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZkJuD_ZTKQm",
        "colab_type": "code",
        "outputId": "9cff0755-212e-4740-a1c7-0d7223a6a4b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!pip3 uninstall torchvision -y\n",
        "!git clone https://github.com/pytorch/vision.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling torchvision-0.2.3a0+d534785:\n",
            "  Successfully uninstalled torchvision-0.2.3a0+d534785\n",
            "fatal: destination path 'vision' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmbt9YjhhB2F",
        "colab_type": "code",
        "outputId": "c753cb60-5678-436b-afd5-c6a16b8d58e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2753
        }
      },
      "source": [
        "!ls\n",
        "%cd vision\n",
        "!python setup.py install\n",
        "%cd ../"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  sample_data  vision\n",
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N837fclzvHcX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "6936aaff-cc6d-499f-ee7d-a81bfc78339e"
      },
      "source": [
        "%ll\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 12\n",
            "drwxr-xr-x  3 root 4096 May  5 11:41 \u001b[0m\u001b[01;34mdata\u001b[0m/\n",
            "drwxr-xr-x  1 root 4096 Apr 29 16:32 \u001b[01;34msample_data\u001b[0m/\n",
            "drwxr-xr-x 10 root 4096 May  5 06:44 \u001b[01;34mvision\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L64kadFYynyx",
        "colab_type": "code",
        "outputId": "65db2637-1d02-4dc1-b58d-69955d152d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        }
      },
      "source": [
        "%ll\n",
        "%cd data\n",
        "!wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_train.tar -c\n",
        "!wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_val.tar -c\n",
        "!wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_devkit_t12.tar.gz -c\n",
        "%cd .."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 12\n",
            "drwxr-xr-x  3 root 4096 May  5 11:41 \u001b[0m\u001b[01;34mdata\u001b[0m/\n",
            "drwxr-xr-x  1 root 4096 Apr 29 16:32 \u001b[01;34msample_data\u001b[0m/\n",
            "drwxr-xr-x 10 root 4096 May  5 06:44 \u001b[01;34mvision\u001b[0m/\n",
            "/content/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s-qJAxUTSmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "class DynamicPruning(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_layer_channels=None):\n",
        "        super(DynamicPruning, self).__init__()\n",
        "\n",
        "        if hidden_layer_channels is None:\n",
        "            hidden_layer_channels = in_channels // 16\n",
        "            if hidden_layer_channels < 4:\n",
        "                hidden_layer_channels = 4\n",
        "\n",
        "        self.gavgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Conv2d(in_channels, hidden_layer_channels,\n",
        "                             kernel_size=1, stride=1)\n",
        "        self.fc2 = nn.Conv2d(hidden_layer_channels,\n",
        "                             in_channels, kernel_size=1, stride=1)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        nn.init.constant_(self.fc1.bias, 0)\n",
        "        nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        nn.init.constant_(self.fc2.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.gavgpool(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = torch.clamp(x, 0, 1)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = torch.clamp(x, 0, 1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class DP_Conv2d(nn.Module):\n",
        "    def __init__(self, in_channels=0, out_channels=0,\n",
        "                 kernel_size=0, stride=1, padding=0, dilation=1,\n",
        "                 groups=1, bias=True, padding_mode='zeros',\n",
        "                 conv2d=None, hidden_layer_channels=None):\n",
        "        super(DP_Conv2d, self).__init__()\n",
        "        if in_channels is 0 or out_channels is 0 or kernel_size is 0:\n",
        "            if conv2d is None:\n",
        "                assert()\n",
        "            else:\n",
        "                self.__init__from_Conv2d(conv2d, hidden_layer_channels)\n",
        "        else:\n",
        "            if hidden_layer_channels is None:\n",
        "                hidden_layer_channels = out_channels // 16\n",
        "                if hidden_layer_channels < 4:\n",
        "                    hidden_layer_channels = 4\n",
        "\n",
        "            self.prun = DynamicPruning(in_channels, hidden_layer_channels)\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels,\n",
        "                                  kernel_size, stride=stride,\n",
        "                                  padding=padding, dilation=dilation,\n",
        "                                  groups=groups, bias=bias,\n",
        "                                  padding_mode=padding_mode)\n",
        "\n",
        "    def __init__from_Conv2d(self, conv2d, hidden_layer_channels=None):\n",
        "        if not isinstance(conv2d, nn.Conv2d):\n",
        "            assert()\n",
        "        if hidden_layer_channels is None:\n",
        "            hidden_layer_channels = conv2d.out_channels // 16\n",
        "            if hidden_layer_channels < 4:\n",
        "                hidden_layer_channels = 4\n",
        "\n",
        "        self.prun = DynamicPruning(\n",
        "            conv2d.in_channels, hidden_layer_channels)\n",
        "        self.conv = conv2d\n",
        "\n",
        "    def forward(self, x):\n",
        "        dp_res = self.prun(x)\n",
        "        x = x * dp_res\n",
        "        x = self.conv(x)\n",
        "\n",
        "        return x\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGd7BnetUKaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1847
        },
        "outputId": "e37861d8-9f66-4872-e4c4-cfc82f901fd3"
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "class FireDP(nn.Module):\n",
        "    def __init__(self, fire):\n",
        "        super(FireDP, self).__init__()\n",
        "\n",
        "        self.squeeze = fire.squeeze\n",
        "        self.squeeze_activation = fire.squeeze_activation\n",
        "\n",
        "        self.expand1x1 = fire.expand1x1\n",
        "        self.expand1x1_activation = fire.expand1x1_activation\n",
        "\n",
        "        self.prun = DynamicPruning(self.squeeze.out_channels)\n",
        "\n",
        "        self.expand3x3 = fire.expand3x3\n",
        "        self.expand3x3_activation = fire.expand3x3_activation\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        dp_res = self.prun(x)\n",
        "        dp_res = dp_res * x\n",
        "\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(dp_res))\n",
        "        ], 1)\n",
        "\n",
        "\n",
        "class SqueezeNet_DP(nn.Module):\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet_DP, self).__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        pretrain_model = models.squeezenet1_1(\n",
        "            pretrained=True, num_classes=num_classes)\n",
        "\n",
        "        self.features = pretrain_model.features\n",
        "        self.features[3] = FireDP(fire=self.features[3])\n",
        "        self.features[4] = FireDP(fire=self.features[4])\n",
        "        self.features[6] = FireDP(fire=self.features[6])\n",
        "        self.features[7] = FireDP(fire=self.features[7])\n",
        "\n",
        "        self.classifier = pretrain_model.classifier\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "print(SqueezeNet_DP())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet_DP(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): FireDP(\n",
            "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (prun): DynamicPruning(\n",
            "        (gavgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (fc2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): FireDP(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (prun): DynamicPruning(\n",
            "        (gavgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (fc2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (6): FireDP(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (prun): DynamicPruning(\n",
            "        (gavgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (fc2): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (7): FireDP(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (prun): DynamicPruning(\n",
            "        (gavgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (fc2): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4bzOuwuUcZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "best_prec1 = 0\n",
        "best_total_num_zeros = 0\n",
        "\n",
        "DP_zeros = 0\n",
        "DP_loss = 0\n",
        "\n",
        "DP_num_zeros_for_each_block = [0, 0, 0, 0]\n",
        "\n",
        "learning_rate = 0.04\n",
        "batch_size = 128\n",
        "epochs = 70\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0002\n",
        "resume = False\n",
        "start_epoch = 0\n",
        "evaluate = False\n",
        "print_freq = 10\n",
        "\n",
        "\n",
        "def main():\n",
        "    global best_prec1, best_total_num_zeros, DP_num_zeros_for_each_block\n",
        "    global learning_rate, batch_size, epochs, momentum, weight_decay\n",
        "    global start_epoch, resume, evaluate\n",
        "\n",
        "    random.seed(271728)\n",
        "    torch.manual_seed(271728)\n",
        "    cudnn.deterministic = True\n",
        "\n",
        "    model = SqueezeNet_DP()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "    optimizer = torch.optim.SGD(filter(\n",
        "        lambda p: p.requires_grad, model.parameters()),\n",
        "        learning_rate,\n",
        "        momentum=momentum,\n",
        "        weight_decay=weight_decay)\n",
        "\n",
        "    if resume:\n",
        "        if os.path.isfile(resume):\n",
        "            print(\"=> loading checkpoint '{}'\".format(resume))\n",
        "            checkpoint = torch.load(resume)\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            best_prec1 = checkpoint['best_prec1']\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "                  .format(resume, checkpoint['epoch']))\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(resume))\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    train_dataset = datasets.ImageNet('./data/', split='train', download=True,\n",
        "                                      transform=transforms.Compose([\n",
        "                                          transforms.RandomResizedCrop(224),\n",
        "                                          transforms.RandomHorizontalFlip(),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          normalize\n",
        "                                      ]))\n",
        "\n",
        "    train_sampler = None\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size,\n",
        "        shuffle=(train_sampler is None),\n",
        "        num_workers=8, pin_memory=True, sampler=train_sampler)\n",
        "\n",
        "    val_dataset = datasets.ImageNet('./data/', split='val', download=True, transform=transforms.Compose(\n",
        "        [transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), normalize]))\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                                             batch_size=batch_size, shuffle=False,\n",
        "                                             num_workers=8, pin_memory=True)\n",
        "\n",
        "    if evaluate:\n",
        "        validate(val_loader, model, criterion)\n",
        "        return\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        train(train_loader, model, criterion, optimizer, epoch)\n",
        "        adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "        prec1 = validate(val_loader, model, criterion)\n",
        "\n",
        "        is_best_acc = prec1 > best_prec1\n",
        "\n",
        "        DP_total_num_zeros = 0\n",
        "        for num_zeros in DP_num_zeros_for_each_block:\n",
        "            DP_total_num_zeros += num_zeros\n",
        "        DP_num_zeros_for_each_block = [0, 0, 0, 0]\n",
        "\n",
        "        is_best_prun = DP_total_num_zeros > best_total_num_zeros\n",
        "\n",
        "        best_prec1 = max(prec1, best_prec1)\n",
        "        best_total_num_zeros = max(DP_total_num_zeros, best_total_num_zeros)\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'best_prec1': best_prec1,\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "        }, is_best_acc, is_best_prun)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywa17N8RaKfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    global DP_loss, DP_zeros\n",
        "    global print_freq\n",
        "\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "\n",
        "    handle_1 = model.features[3].prun.register_forward_hook(DP_results_train)\n",
        "    handle_2 = model.features[4].prun.register_forward_hook(DP_results_train)\n",
        "    handle_3 = model.features[6].prun.register_forward_hook(DP_results_train)\n",
        "    handle_4 = model.features[7].prun.register_forward_hook(DP_results_train)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        output = model(input)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        print(loss, loss+DP_loss)\n",
        "        loss += DP_loss\n",
        "\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
        "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                      data_time=data_time, loss=losses))\n",
        "\n",
        "        DP_loss = 0\n",
        "        DP_zeros = 0\n",
        "\n",
        "    handle_1.remove()\n",
        "    handle_2.remove()\n",
        "    handle_3.remove()\n",
        "    handle_4.remove()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS1uDDWHlnwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(val_loader, model, criterion):\n",
        "    global DP_zeros, DP_num_zeros_for_each_block, DP_loss\n",
        "    global print_freq\n",
        "\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    dp_losses = AverageMeter()\n",
        "    dp_zeros = AverageMeter()\n",
        "\n",
        "    handle1 = model.features[3].prun.register_forward_hook(DP_get_num_zeros_1)\n",
        "    handle2 = model.features[4].prun.register_forward_hook(DP_get_num_zeros_2)\n",
        "    handle3 = model.features[6].prun.register_forward_hook(DP_get_num_zeros_3)\n",
        "    handle4 = model.features[7].prun.register_forward_hook(DP_get_num_zeros_4)\n",
        "\n",
        "    handle_1 = model.features[3].prun.register_forward_hook(DP_results)\n",
        "    handle_2 = model.features[4].prun.register_forward_hook(DP_results)\n",
        "    handle_3 = model.features[6].prun.register_forward_hook(DP_results)\n",
        "    handle_4 = model.features[7].prun.register_forward_hook(DP_results)\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        end = time.time()\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "            loss += DP_loss\n",
        "\n",
        "            prec1, prec5 = accuracy(output, target, topk=(1, 5))\n",
        "\n",
        "            losses.update(loss.item(), input.size(0))\n",
        "            dp_losses.update(DP_loss)\n",
        "            dp_zeros.update(DP_zeros)\n",
        "            top1.update(prec1[0], input.size(0))\n",
        "            top5.update(prec5[0], input.size(0))\n",
        "\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            print('Test: [{0}/{1}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'DP_Loss {dp_loss.val:.4f} ({dp_loss.avg:.4f})\\t'\n",
        "                  'Number of zeros {num.val} ({num.avg:.3f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
        "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
        "                      i, len(val_loader), batch_time=batch_time, loss=losses,\n",
        "                      dp_loss=dp_losses, num=dp_zeros,\n",
        "                      top1=top1, top5=top5))\n",
        "\n",
        "            DP_loss = 0\n",
        "            DP_zeros = 0\n",
        "\n",
        "            if i == len(val_loader) - 1:\n",
        "                last_bs = output.size(0)\n",
        "\n",
        "        handle1.remove()\n",
        "        handle2.remove()\n",
        "        handle3.remove()\n",
        "        handle4.remove()\n",
        "\n",
        "        handle_1.remove()\n",
        "        handle_2.remove()\n",
        "        handle_3.remove()\n",
        "        handle_4.remove()\n",
        "\n",
        "        DP_percentage_zeros_for_each_block = []\n",
        "        DP_percentage_zeros_for_each_block.append(\n",
        "            DP_num_zeros_for_each_block[0] / (\n",
        "                ((len(val_loader) - 1) * args.batch_size + last_bs) * 16\n",
        "            )\n",
        "        )\n",
        "        DP_percentage_zeros_for_each_block.append(\n",
        "            DP_num_zeros_for_each_block[1] / (\n",
        "                ((len(val_loader) - 1) * args.batch_size + last_bs) * 16\n",
        "            )\n",
        "        )\n",
        "        DP_percentage_zeros_for_each_block.append(\n",
        "            DP_num_zeros_for_each_block[2] / (\n",
        "                ((len(val_loader) - 1) * args.batch_size + last_bs) * 32\n",
        "            )\n",
        "        )\n",
        "        DP_percentage_zeros_for_each_block.append(\n",
        "            DP_num_zeros_for_each_block[3] / (\n",
        "                ((len(val_loader) - 1) * args.batch_size + last_bs) * 32\n",
        "            )\n",
        "        )\n",
        "\n",
        "        print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
        "              .format(top1=top1, top5=top5))\n",
        "        print('\\t', DP_percentage_zeros_for_each_block)\n",
        "\n",
        "    return top1.avg\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi92y_nWmAgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DP_results(self, input, output):\n",
        "    global DP_zeros, DP_loss\n",
        "    vec = output\n",
        "    vec = vec.cpu()\n",
        "\n",
        "    for i in vec.view(-1):\n",
        "        if i == 0:\n",
        "            DP_zeros += 1\n",
        "\n",
        "    DP_loss += torch.dist(vec.mean(), torch.tensor(0.5))\n",
        "\n",
        "\n",
        "def DP_results_train(self, input, output):\n",
        "    global DP_loss\n",
        "    vec = output\n",
        "    vec = vec.cpu()\n",
        "\n",
        "    DP_loss += torch.dist(vec.mean(), torch.tensor(0.5))\n",
        "\n",
        "\n",
        "def DP_get_num_zeros_1(self, input, output):\n",
        "    global DP_num_zeros_for_each_block\n",
        "    vec = output\n",
        "    vec = vec.cpu()\n",
        "    for i in vec.view(-1):\n",
        "        if i == 0:\n",
        "            DP_num_zeros_for_each_block[0] += 1\n",
        "\n",
        "\n",
        "def DP_get_num_zeros_2(self, input, output):\n",
        "    global DP_num_zeros_for_each_block\n",
        "    vec = output\n",
        "    vec = vec.cpu()\n",
        "    for i in vec.view(-1):\n",
        "        if i == 0:\n",
        "            DP_num_zeros_for_each_block[1] += 1\n",
        "\n",
        "\n",
        "def DP_get_num_zeros_3(self, input, output):\n",
        "    global DP_num_zeros_for_each_block\n",
        "    vec = output\n",
        "    vec = vec.cpu()\n",
        "    for i in vec.view(-1):\n",
        "        if i == 0:\n",
        "            DP_num_zeros_for_each_block[2] += 1\n",
        "\n",
        "\n",
        "def DP_get_num_zeros_4(self, input, output):\n",
        "    global DP_num_zeros_for_each_block\n",
        "    vec = output\n",
        "    vec = vec.cpu()\n",
        "    for i in vec.view(-1):\n",
        "        if i == 0:\n",
        "            DP_num_zeros_for_each_block[3] += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXKSnH5jmGE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(state, is_best_acc, is_best_prun,\n",
        "                    filename='../DP_SqueezeNet/checkpoint.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "    if is_best_acc:\n",
        "        shutil.copyfile(filename,\n",
        "                        '../DP_SqueezeNet/model_best_acc.pth.tar')\n",
        "    if is_best_prun:\n",
        "        shutil.copyfile(filename,\n",
        "                        '../DP_SqueezeNet/model_best_prun.pth.tar')\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 15 epochs\"\"\"\n",
        "    lr = args.lr * (0.1 ** (epoch // 15))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTb7mkm6mOCB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8151
        },
        "outputId": "432ace87-8af6-4403-b1f3-029800b7a42e"
      },
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You set download=True, but a folder 'train' already exist in the root directory. If you want to re-download or re-extract the archive, delete the folder.\n",
            "tensor(8.1584, grad_fn=<NllLossBackward>) tensor(9.4732, grad_fn=<AddBackward0>)\n",
            "Epoch: [0][0/8271]\tTime 33.961 (33.961)\tData 20.083 (20.083)\tLoss 9.4732 (9.4732)\t\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
